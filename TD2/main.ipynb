{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Team Work 2 : Spam Filtering\n",
    "\n",
    "**Authors:** CHRETIEN Jérémy, DAVIDSON Colin, LAFAGE Adrien, REMBUSCH Gabrielle and WILBRINK Aurore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "[nltk_data] Downloading package stopwords to /home/eisti/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n[nltk_data] Downloading package punkt to /home/eisti/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords as stpw\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Starts time count**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Loads data from CSV file.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "  labels                                           contents\n0    ham  Go until jurong point, crazy.. Available only ...\n1    ham                      Ok lar... Joking wif u oni...\n2   spam  Free entry in 2 a wkly comp to win FA Cup fina...\n3    ham  U dun say so early hor... U c already then say...\n4    ham  Nah I don't think he goes to usf, he lives aro...",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>labels</th>\n      <th>contents</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ham</td>\n      <td>Go until jurong point, crazy.. Available only ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ham</td>\n      <td>Ok lar... Joking wif u oni...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>spam</td>\n      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ham</td>\n      <td>U dun say so early hor... U c already then say...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ham</td>\n      <td>Nah I don't think he goes to usf, he lives aro...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "data = pd.read_csv(\"SMS_source.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "3915 training instances (~70%).\n1659 testing instances (~30%).\n"
    }
   ],
   "source": [
    "np.random.seed(0) # to get the same randomness\n",
    "threshold = np.random.rand(len(data)) < 0.7\n",
    "train_set = data[threshold]\n",
    "test_set = data[~threshold]\n",
    "print(f\"{len(train_set)} training instances (~70%).\\n{len(test_set)} testing instances (~30%).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train split distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "ham: 86.54%\nspam: 13.46%\n"
    }
   ],
   "source": [
    "ham_prop = len(train_set[train_set.labels == \"ham\"])/len(train_set) * 100\n",
    "spam_prop = len(train_set[train_set.labels == \"spam\"])/len(train_set) * 100\n",
    "\n",
    "print(f\"ham: {ham_prop:.4}%\\nspam: {spam_prop:.4}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test split distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "ham: 86.74%\nspam: 13.26%\n"
    }
   ],
   "source": [
    "ham_prop = len(test_set[test_set.labels == \"ham\"])/len(test_set) * 100\n",
    "spam_prop = len(test_set[test_set.labels == \"spam\"])/len(test_set) * 100\n",
    "\n",
    "print(f\"ham: {ham_prop:.4}%\\nspam: {spam_prop:.4}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(content):\n",
    "    content = content.lower()\n",
    "    content = content.translate(str.maketrans(\"\",\"\", string.punctuation))\n",
    "    content = re.sub(r'\\d+ *|\\b[a-z]\\b *', \"\", content) # remove isolated letters\n",
    "    content = content.strip()\n",
    "    tokens = word_tokenize(content)\n",
    "    stopwords = set(stpw.words(\"english\"))\n",
    "    # removes stopwords and duplicates\n",
    "    content = \" \".join(\n",
    "        list(dict.fromkeys([t for t in tokens if not t in stopwords]))\n",
    "    )\n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_set.contents = train_set.contents.apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "  labels                                           contents\n0    ham  go jurong point crazy available bugis great wo...\n2   spam  free entry wkly comp win fa cup final tkts st ...\n3    ham                          dun say early hor already\n4    ham        nah dont think goes usf lives around though\n5   spam  freemsg hey darling weeks word back id like fu...",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>labels</th>\n      <th>contents</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ham</td>\n      <td>go jurong point crazy available bugis great wo...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>spam</td>\n      <td>free entry wkly comp win fa cup final tkts st ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ham</td>\n      <td>dun say early hor already</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ham</td>\n      <td>nah dont think goes usf lives around though</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>spam</td>\n      <td>freemsg hey darling weeks word back id like fu...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "train_set.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Splits train set by labels.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Number of spam instances: 527.\nNumber of ham instances: 3388.\n"
    }
   ],
   "source": [
    "spam_data = train_set[train_set.labels == \"spam\"]\n",
    "spam_freq = len(spam_data)/len(train_set)\n",
    "ham_data = train_set[train_set.labels == \"ham\"]\n",
    "ham_freq = len(ham_data)/len(train_set)\n",
    "print(f\"Number of spam instances: {len(spam_data)}.\\nNumber of ham instances: {len(ham_data)}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Computes word occurences for each class.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Spam\n",
    "spam_contents = (\" \".join(spam_data.contents)).split(\" \")\n",
    "uniq_words = list(dict.fromkeys(spam_contents))\n",
    "occurence_spam_data = pd.DataFrame(\n",
    "    {\n",
    "        'word': uniq_words,\n",
    "        'occurence': [ spam_contents.count(word) for word in uniq_words],\n",
    "    }\n",
    ")\n",
    "occurence_spam_data = occurence_spam_data.sort_values(by=\"occurence\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ham\n",
    "ham_contents = (\" \".join(ham_data.contents)).split(\" \")\n",
    "uniq_words = list(dict.fromkeys(ham_contents))\n",
    "occurence_ham_data = pd.DataFrame(\n",
    "    {\n",
    "        'word': uniq_words,\n",
    "        'occurence': [ ham_contents.count(word) for word in uniq_words],\n",
    "    }\n",
    ")\n",
    "occurence_ham_data = occurence_ham_data.sort_values(by=\"occurence\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Concatenates the words of each class into one list avoiding duplicates.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Total number of words: 7148.\n"
    }
   ],
   "source": [
    "uniq_words = list(dict.fromkeys(list(occurence_ham_data.word)+list(occurence_spam_data.word)))\n",
    "print(f\"Total number of words: {len(uniq_words)}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Creates the final DataFrame used in the next section. (it takes some time)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "  words  ham  spam\n0    im  291     7\n1   get  223    53\n2    ok  173     3\n3    go  168    21\n4  dont  167    15",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>words</th>\n      <th>ham</th>\n      <th>spam</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>im</td>\n      <td>291</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>get</td>\n      <td>223</td>\n      <td>53</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ok</td>\n      <td>173</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>go</td>\n      <td>168</td>\n      <td>21</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>dont</td>\n      <td>167</td>\n      <td>15</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "knowledge = pd.DataFrame(\n",
    "    {\n",
    "        \"words\": uniq_words,\n",
    "        \"ham\": [\n",
    "            occurence_ham_data[occurence_ham_data.word == word].occurence.item()\n",
    "            if len(occurence_ham_data[occurence_ham_data.word == word]) > 0 else 0\n",
    "            for word in uniq_words\n",
    "        ],\n",
    "        \"spam\": [\n",
    "            occurence_spam_data[occurence_spam_data.word == word].occurence.item()\n",
    "            if len(occurence_spam_data[occurence_spam_data.word == word]) > 0 else 0\n",
    "            for word in uniq_words\n",
    "        ]\n",
    "    }\n",
    ")\n",
    "\n",
    "knowledge.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   labels                                           contents\n1     ham                              ok lar joking wif oni\n7     ham  per request melle oru minnaminunginte nurungu ...\n8    spam  winner valued network customer selected receiv...\n10    ham  im gon na home soon dont want talk stuff anymo...\n13    ham  ive searching right words thank breather promi...",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>labels</th>\n      <th>contents</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>ham</td>\n      <td>ok lar joking wif oni</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>ham</td>\n      <td>per request melle oru minnaminunginte nurungu ...</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>spam</td>\n      <td>winner valued network customer selected receiv...</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>ham</td>\n      <td>im gon na home soon dont want talk stuff anymo...</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>ham</td>\n      <td>ive searching right words thank breather promi...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "test_set.contents = test_set.contents.apply(preprocess)\n",
    "test_set.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayes:\n",
    "    \"\"\"\n",
    "    Classificator based on Naive Bayes' method to make predictions on tweets (Spam filtering)\n",
    "    Parameters\n",
    "    ----------\n",
    "    knowledge: Pandas DataFrame\n",
    "        DataFrame of the word occurences for each label/class.\n",
    "    labels: Pandas Series\n",
    "        Serie of labels.\n",
    "    \"\"\"\n",
    "    def __init__(self, knowledge, labels):\n",
    "        self.knowledge = knowledge\n",
    "        self.labels = labels\n",
    "        self.alpha = 1\n",
    "        self.N = len(self.knowledge.words)\n",
    "        self.priors = self.computes_priors(self.labels)\n",
    "\n",
    "    def computes_priors(self, labels):\n",
    "        \"\"\" Computes prior probabilities.\n",
    "        Parameter\n",
    "        ---------\n",
    "        labels: Pandas Series\n",
    "            Serie of labels.\n",
    "        Recall\n",
    "        ------\n",
    "        prior is P(label=l_i).\n",
    "        \"\"\"\n",
    "        priors = []\n",
    "        for count in labels.value_counts():\n",
    "            priors.append(count/len(labels))            \n",
    "\n",
    "        return priors\n",
    "\n",
    "    def computes_likelihood(self, word, label):\n",
    "        \"\"\" Computes likelihood of the existence of a word in a sentence\n",
    "        knowing a the sentence's label.\n",
    "        Parameters\n",
    "        ----------\n",
    "        word: string\n",
    "\n",
    "        label: string\n",
    "        \"\"\"\n",
    "        occ = self.knowledge.loc[self.knowledge.words == word, label].item()\n",
    "        total = self.labels.value_counts()[label]\n",
    "        \n",
    "        return (occ + self.alpha) / (total + self.alpha * self.N)\n",
    "\n",
    "    def predict(self, sentence):\n",
    "        \"\"\" Predicts a label for a sentence.\n",
    "        Parameter\n",
    "        ---------\n",
    "        sentence: string list.\n",
    "        \"\"\"\n",
    "        ham_p = self.priors[0]\n",
    "        spam_p = self.priors[1]\n",
    "\n",
    "        for word in sentence:\n",
    "            if word in list(self.knowledge.words):\n",
    "                ham_p *= self.computes_likelihood(word, \"ham\")\n",
    "                spam_p *= self.computes_likelihood(word, \"spam\")\n",
    "        \n",
    "        if ham_p > spam_p:\n",
    "            return \"ham\"\n",
    "        elif spam_p > ham_p:\n",
    "            return \"spam\"\n",
    "        else:\n",
    "            return \"unknown\"\n",
    "\n",
    "    def accuracy(self, predicted, expected):\n",
    "        \"\"\" Computes accuracy according to both lists of\n",
    "        expected and predicted values.\n",
    "        Parameters\n",
    "        ----------\n",
    "        predicted: list\n",
    "\n",
    "        expected: list\n",
    "        \"\"\"\n",
    "        data = pd.DataFrame({\n",
    "            'expected': expected,\n",
    "            'predicted': predicted\n",
    "        })\n",
    "        return len(data[data.expected == data.predicted])/len(data)\n",
    "\n",
    "    def precision(self, predicted, expected, label):\n",
    "        \"\"\" Computes the precision on a label according to\n",
    "        both lists of expected and predicted values.\n",
    "        Parameters\n",
    "        ----------\n",
    "        predicted: list\n",
    "\n",
    "        expected: list\n",
    "\n",
    "        label: string\n",
    "        \"\"\"\n",
    "        data = pd.DataFrame({\n",
    "            'expected': expected,\n",
    "            'predicted': predicted\n",
    "        })\n",
    "        data = data[data.expected == label]\n",
    "        return len(data[data.expected == data.predicted])/len(data)\n",
    "\n",
    "    def recall(self, predicted, expected, label):\n",
    "        \"\"\" Computes recall on a label according to both lists\n",
    "        of expected and predicted values.\n",
    "        Parameters\n",
    "        ----------\n",
    "        predicted: list\n",
    "\n",
    "        expected: list\n",
    "\n",
    "        label: string\n",
    "        \"\"\"\n",
    "        data = pd.DataFrame({\n",
    "            'expected': expected,\n",
    "            'predicted': predicted\n",
    "        })\n",
    "        data = data[data.predicted == label]\n",
    "        return len(data[data.expected == data.predicted])/len(data)\n",
    "\n",
    "    def f1_score(self, predicted, expected, label):\n",
    "        \"\"\" Computes F1 score on a label according to both lists of\n",
    "        expected and predicted values.\n",
    "        Parameters\n",
    "        ----------\n",
    "        predicted: list\n",
    "\n",
    "        expected: list\n",
    "\n",
    "        label: string\n",
    "        \"\"\"\n",
    "        precision_ = self.precision(predicted, expected, label)\n",
    "        recall_ = self.recall(predicted, expected, label)\n",
    "        return 2 * (precision_*recall_) / (precision_ + recall_)\n",
    "\n",
    "    def eval(self, predicted, expected):\n",
    "        \"\"\"\n",
    "        Prints infos on classificator's efficiency based on expectations and results\n",
    "        \"\"\"\n",
    "        print(f\"Acccuracy: {self.accuracy(predicted, expected)}\")\n",
    "        print(f\"Precision on ham label: {self.precision(predicted, expected, 'ham')}\")\n",
    "        print(f\"Precision on spam label: {self.precision(predicted, expected, 'spam')}\")\n",
    "        print(f\"Recall on ham label: {self.recall(predicted, expected, 'ham')}\")\n",
    "        print(f\"Recall on spam label: {self.recall(predicted, expected, 'spam')}\")\n",
    "        print(f\"F1 score on ham label: {self.f1_score(predicted, expected, 'ham')}\")\n",
    "        print(f\"F1 score on spam label: {self.f1_score(predicted, expected, 'spam')}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = NaiveBayes(knowledge, train_set.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'ham'"
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "clf.predict([\"im\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'spam'"
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "clf.predict([\"call\", \"free\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test classifier performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "expected = list(test_set.labels)\n",
    "predicted = [clf.predict(sentence.split(\" \")) for sentence in test_set.contents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Acccuracy: 0.9783001808318263\nPrecision on ham label: 1.0\nPrecision on spam label: 0.8363636363636363\nRecall on ham label: 0.9755932203389831\nRecall on spam label: 1.0\nF1 score on ham label: 0.9876458476321209\nF1 score on spam label: 0.9108910891089108\n"
    }
   ],
   "source": [
    "clf.eval(predicted, expected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Time performance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Execution time : 85.97044634819031\n"
    }
   ],
   "source": [
    "print(\"Execution time : \" + str(time.time() - start))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}